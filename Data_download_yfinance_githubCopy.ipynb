{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d358122-d4b6-4cab-84ea-8862bcc2df10",
   "metadata": {},
   "source": [
    "## Historical Daily Closing Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89622c68-a813-44b0-95b5-9c797b88de0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# List of tickers\n",
    "tickers = [ \"Input all stocks Nifty list\" ]\n",
    "       \n",
    "# Create an empty DataFrame to hold the results\n",
    "quarterly_data = pd.DataFrame()\n",
    "\n",
    "# Define the date range\n",
    "start_date = '2006-03-01'\n",
    "end_date = '2024-06-30'\n",
    "\n",
    "# Month name mapping\n",
    "month_mapping = {\n",
    "    1: 'Jan',\n",
    "    2: 'Feb',\n",
    "    3: 'Mar',\n",
    "    4: 'Apr',\n",
    "    5: 'May',\n",
    "    6: 'Jun',\n",
    "    7: 'Jul',\n",
    "    8: 'Aug',\n",
    "    9: 'Sep',\n",
    "    10: 'Oct',\n",
    "    11: 'Nov',\n",
    "    12: 'Dec'\n",
    "}\n",
    "\n",
    "# Loop through each ticker to get the quarterly closing prices\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        # Fetch historical data for the specified ticker\n",
    "        data = yf.download(ticker, start=start_date, end=end_date, interval='1d')\n",
    "        \n",
    "        # Check if data is empty\n",
    "        if data.empty:\n",
    "            print(f\"No data found for {ticker}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Resample the data to get quarterly closing prices using 'QE'\n",
    "        quarterly_prices = data['Close'].resample('D').last()  # Take the last closing price of each quarter\n",
    "        \n",
    "        # Create a DataFrame with Month and Year columns\n",
    "        quarterly_df = quarterly_prices.reset_index()\n",
    "        quarterly_df['Month'] = quarterly_df['Date'].dt.month\n",
    "        quarterly_df['Year'] = quarterly_df['Date'].dt.year\n",
    "        quarterly_df['Ticker'] = ticker  # Add the ticker column\n",
    "\n",
    "        # Map month numbers to month names\n",
    "        quarterly_df['Month'] = quarterly_df['Month'].map(month_mapping)\n",
    "        \n",
    "        # Select only the necessary columns\n",
    "        #quarterly_df = quarterly_df[['Ticker', 'Month', 'Year', 'Close']]\n",
    "        \n",
    "        # Append the results to the main DataFrame\n",
    "        quarterly_data = pd.concat([quarterly_data, quarterly_df], ignore_index=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {e}\")\n",
    "\n",
    "# Save the resulting DataFrame to a CSV file\n",
    "quarterly_data.to_csv(r'your_file_path', index=False)\n",
    "\n",
    "# Display a message indicating the file has been created\n",
    "print(\"Quarterly closing prices have been saved to 'quarterly_closing_prices.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c39a154-8cc0-4b86-847d-0ca845c74702",
   "metadata": {},
   "source": [
    "## Nifty Index Futures hourly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0164739-2bca-4a54-9998-d62e9944d98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['^NSEI']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1h 2021-03-01 -> 2023-02-01) (Yahoo error = \"1h data not available for startTime=1614537000 and endTime=1675189800. The requested range must be within the last 730 days.\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Define the Nifty 50 ticker symbol\n",
    "nifty_ticker = \"^NSEI\"  # \"^NSEI\" is the ticker symbol for Nifty 50 Index on Yahoo Finance\n",
    "\n",
    "# Download historical data\n",
    "nifty_data = yf.download(nifty_ticker, start=\"2023-03-01\", end=\"2025-02-01\", interval=\"1h\")\n",
    "\n",
    "# Save the data to a CSV file\n",
    "nifty_data.to_csv(\"nifty_historical_data.csv\", index=True)\n",
    "\n",
    "# Print a summary of the data\n",
    "print(nifty_data.head())\n",
    "\n",
    "output_file_path = r'your_file_path'\n",
    "nifty_data.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1841fba5-530c-4213-bcc5-78e0d6a32788",
   "metadata": {},
   "source": [
    "# Cashflow statement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10ad8b5-143e-4b44-8de8-2d907a781036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to your CSV file containing the tickers\n",
    "file_path = 'your_file_path'\n",
    "\n",
    "# Read the CSV file to get the tickers (assuming tickers are in the first column)\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming the tickers are in the first column, adjust the column name accordingly\n",
    "tickers = df.iloc[:, 0].tolist()\n",
    "\n",
    "# Create a dictionary to store the cash flow statement data for each ticker\n",
    "cash_flow_data = {}\n",
    "\n",
    "# Create output directory\n",
    "output_directory = r'your_file_path'\n",
    "output_dir = os.path.join(output_directory, r'snp_500_data')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "counter = 1\n",
    "\n",
    "# Download the quarterly cash flow statement data for each ticker\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        company = yf.Ticker(ticker)\n",
    "        \n",
    "        # Get the quarterly cash flow statement data (limited to the last 5 quarters)\n",
    "        cash_flow_statement = company.quarterly_cashflow\n",
    "        \n",
    "        # Output dataset\n",
    "        output_file_path = os.path.join(output_dir, f\"{ticker}_cashflow_batch_{counter}.csv\")\n",
    "        cash_flow_statement.to_csv(output_file_path)\n",
    "\n",
    "        counter += 1\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Could not fetch data for {ticker}: {e}\")\n",
    "        cash_flow_data[ticker] = None  # Mark the ticker as not available\n",
    "\n",
    "# Combine all cash flow statement data into a single DataFrame\n",
    "#combined_cash_flow_statement = pd.concat(cash_flow_data.values(), keys=cash_flow_data.keys(), axis=1)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "#combined_cash_flow_statement.to_csv('SnP500_quarterly_cash_flow_statement.csv')\n",
    "\n",
    "print(f\"Quarterly cash flow statement data (last 5 quarters) has been saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9166f8-a6f3-4bc6-9ab0-1db1517f43e4",
   "metadata": {},
   "source": [
    "# Income Statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05bdb0c-7097-4690-abbd-320a938a978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to your CSV file containing the tickers\n",
    "file_path = 'your_file_path'\n",
    "\n",
    "# Read the CSV file to get the tickers (assuming tickers are in the first column)\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming the tickers are in the first column, adjust the column name accordingly\n",
    "tickers = df.iloc[:, 0].tolist()\n",
    "\n",
    "# Create a dictionary to store the cash flow statement data for each ticker\n",
    "cash_flow_data = {}\n",
    "\n",
    "# Create output directory\n",
    "output_directory = r'your_file_path'\n",
    "output_dir = os.path.join(output_directory, r'snp_500_data')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "counter = 1\n",
    "\n",
    "# Download the quarterly cash flow statement data for each ticker\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        company = yf.Ticker(ticker)\n",
    "        \n",
    "        # Get the quarterly cash flow statement data (limited to the last 5 quarters)\n",
    "        cash_flow_statement = company.quarterly_income_stmt\n",
    "        \n",
    "        # Output dataset\n",
    "        output_file_path = os.path.join(output_dir, f\"{ticker}_incomestmt_batch_{counter}.csv\")\n",
    "        cash_flow_statement.to_csv(output_file_path)\n",
    "\n",
    "        counter += 1\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Could not fetch data for {ticker}: {e}\")\n",
    "        cash_flow_data[ticker] = None  # Mark the ticker as not available\n",
    "\n",
    "# Combine all cash flow statement data into a single DataFrame\n",
    "#combined_cash_flow_statement = pd.concat(cash_flow_data.values(), keys=cash_flow_data.keys(), axis=1)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "#combined_cash_flow_statement.to_csv('SnP500_quarterly_cash_flow_statement.csv')\n",
    "\n",
    "print(f\"Quarterly income statement data (last 5 quarters) has been saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7847cf-b58c-4186-8b8f-ba7d68336596",
   "metadata": {},
   "source": [
    "# Balance Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d593fd-ebfa-4fc8-a2ed-d4916af1c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to your CSV file containing the tickers\n",
    "file_path = 'your_file_path'\n",
    "\n",
    "# Read the CSV file to get the tickers (assuming tickers are in the first column)\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming the tickers are in the first column, adjust the column name accordingly\n",
    "tickers = df.iloc[:, 0].tolist()\n",
    "\n",
    "# Create a dictionary to store the cash flow statement data for each ticker\n",
    "cash_flow_data = {}\n",
    "\n",
    "# Create output directory\n",
    "output_directory = r'your_file_path'\n",
    "output_dir = os.path.join(output_directory, r'snp_500_data_quaterly')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "counter = 1\n",
    "\n",
    "# Download the quarterly cash flow statement data for each ticker\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        company = yf.Ticker(ticker)\n",
    "        \n",
    "        # Get the quarterly cash flow statement data (limited to the last 5 quarters)\n",
    "        cash_flow_statement = company.quarterly_balance_sheet\n",
    "        \n",
    "        # Output dataset\n",
    "        output_file_path = os.path.join(output_dir, f\"{ticker}_balancesheet_batch_{counter}.csv\")\n",
    "        cash_flow_statement.to_csv(output_file_path)\n",
    "\n",
    "        counter += 1\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Could not fetch data for {ticker}: {e}\")\n",
    "        cash_flow_data[ticker] = None  # Mark the ticker as not available\n",
    "\n",
    "# Combine all cash flow statement data into a single DataFrame\n",
    "#combined_cash_flow_statement = pd.concat(cash_flow_data.values(), keys=cash_flow_data.keys(), axis=1)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "#combined_cash_flow_statement.to_csv('SnP500_quarterly_cash_flow_statement.csv')\n",
    "\n",
    "print(f\"Quarterly balance sheet data (last 5 quarters) has been saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7b59ca-9e99-4dde-ba3b-3cebbf87c45a",
   "metadata": {},
   "source": [
    "# Annual data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1729f46-6502-4ff1-a45e-acd27dd4f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to your CSV file containing the tickers\n",
    "file_path = 'your_file_path'\n",
    "\n",
    "# Read the CSV file to get the tickers (assuming tickers are in the first column)\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming the tickers are in the first column, adjust the column name accordingly\n",
    "tickers = df.iloc[:, 0].tolist()\n",
    "\n",
    "# Create a dictionary to store the cash flow statement data for each ticker\n",
    "cash_flow_data = {}\n",
    "\n",
    "# Create output directory\n",
    "output_directory = r'your_file_path'\n",
    "output_dir = os.path.join(output_directory, r'snp_500_data_annual')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "counter = 1\n",
    "\n",
    "# Download the quarterly cash flow statement data for each ticker\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        company = yf.Ticker(ticker)\n",
    "        \n",
    "        # Get the annual data (limited to the last 5 quarters)\n",
    "        balance_sheet = company.balance_sheet\n",
    "        cash_flow = company.cashflow\n",
    "        income_stmt = company.financials\n",
    "        \n",
    "        # Output dataset\n",
    "        output_file_path_1 = os.path.join(output_dir, f\"{ticker}_a_balancesheet_batch_{counter}.csv\")\n",
    "        balance_sheet.to_csv(output_file_path_1)\n",
    "\n",
    "        output_file_path_2 = os.path.join(output_dir, f\"{ticker}_a_cashflow_batch_{counter}.csv\")\n",
    "        cash_flow.to_csv(output_file_path_2)\n",
    "\n",
    "        output_file_path_3 = os.path.join(output_dir, f\"{ticker}_a_incomestmt_batch_{counter}.csv\")\n",
    "        income_stmt.to_csv(output_file_path_3)\n",
    "        \n",
    "        counter += 1\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Could not fetch data for {ticker}: {e}\")\n",
    "        cash_flow_data[ticker] = None  # Mark the ticker as not available\n",
    "\n",
    "# Combine all cash flow statement data into a single DataFrame\n",
    "#combined_cash_flow_statement = pd.concat(cash_flow_data.values(), keys=cash_flow_data.keys(), axis=1)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "#combined_cash_flow_statement.to_csv('SnP500_quarterly_cash_flow_statement.csv')\n",
    "\n",
    "print(f\"Quarterly balance sheet data (last 5 quarters) has been saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f438879-3d1d-4d59-a830-4a723217accb",
   "metadata": {},
   "source": [
    "# Code to merge all quaterly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21783dad-33da-47fc-85d8-7c6b0329961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Directory where csv files are located\n",
    "input_directory = r'your_file_path'\n",
    "\n",
    "# Output file path\n",
    "output_file_path = r'your_file_path'\n",
    "\n",
    "# Initialize an empty dataframe\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "# Loop thru csv files matching the pattern\n",
    "file_paths = glob.glob(os.path.join(input_directory, \"*_cashflow_batch_*.csv\"))\n",
    "\n",
    "for file in file_paths:\n",
    "\n",
    "    # Extract the stock name\n",
    "    stock_name = os.path.basename(file).split(\"_cashflow_batch_\")[0]\n",
    "\n",
    "    df = pd.read_csv(file, index_col=False)\n",
    "\n",
    "    transpose_df = df.transpose()\n",
    "\n",
    "    transpose_df.reset_index(inplace=True)\n",
    "\n",
    "    # adding new column for the stock name\n",
    "    transpose_df['stock_name'] = stock_name\n",
    "\n",
    "    # check whether the column exists in the combined dataframe, if not then add that column as a new column\n",
    "    for column in transpose_df.columns:\n",
    "        if column not in combined_data.columns:\n",
    "            transpose_df[column] = None\n",
    "            \n",
    "    # Append data to the combined dataframe\n",
    "    combined_data = pd.concat([combined_data, transpose_df], ignore_index=True)\n",
    "\n",
    "    print(f\"datafile {file} is merged with the dataframe\")\n",
    "\n",
    "# output combined dataset\n",
    "combined_data.to_csv(output_file_path)\n",
    "\n",
    "combined_data.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c919ad41-2f49-42c6-8301-b67e46a6e367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the combined dataframe with empty columns\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "# This will be used to track all unique columns across all files\n",
    "all_columns = set()\n",
    "\n",
    "# First pass: Identify all unique columns across all files\n",
    "for file in file_paths:\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file, index_col=False)\n",
    "\n",
    "    # Track all columns from the current file\n",
    "    all_columns.update(df.columns)\n",
    "\n",
    "# Convert the set of columns into a list (for consistent ordering)\n",
    "all_columns = list(all_columns)\n",
    "\n",
    "# Second pass: Read each file, align columns and append data to the combined dataframe\n",
    "for file in file_paths:\n",
    "    # Extract the stock name\n",
    "    stock_name = os.path.basename(file).split(\"_cashflow_batch_\")[0]\n",
    "\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file, index_col=False)\n",
    "\n",
    "    # Transpose the dataframe\n",
    "    transpose_df = df.transpose()\n",
    "\n",
    "    # Reset the index of the transposed dataframe\n",
    "    transpose_df.reset_index(inplace=True)\n",
    "\n",
    "    # Rename the index column to make it more meaningful\n",
    "    transpose_df.rename(columns={'index': 'column_name'}, inplace=True)\n",
    "\n",
    "    # Add the 'stock_name' column\n",
    "    transpose_df['stock_name'] = stock_name\n",
    "\n",
    "    # Reorder columns to match the unified column list, fill missing columns with None (NaN)\n",
    "    for column in all_columns:\n",
    "        if column not in transpose_df.columns:\n",
    "            transpose_df[column] = None\n",
    "\n",
    "    # Reorder the columns to maintain a consistent order\n",
    "    transpose_df = transpose_df[['stock_name'] + [col for col in all_columns]]\n",
    "\n",
    "    # Append the data to the combined dataframe\n",
    "    combined_data = pd.concat([combined_data, transpose_df], ignore_index=True)\n",
    "\n",
    "    print(f\"Datafile {file} is merged with the dataframe\")\n",
    "\n",
    "# Optionally, print the resulting dataframe\n",
    "print(combined_data.head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d34fcd-596f-4a6d-b7ce-12a2a5a0eeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "all_columns = []\n",
    "\n",
    "for file in file_paths:\n",
    "    # Read the entire CSV file (no need to skip rows)\n",
    "    df = pd.read_csv(file, index_col=False)\n",
    "    \n",
    "    # Remove columns whose name contains 'Unnamed'\n",
    "    #df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "    \n",
    "    # Transpose the dataframe\n",
    "    df_transpose = df.transpose()\n",
    "    \n",
    "    # Append the columns of the transposed dataframe (these are now the column names)\n",
    "    all_columns.append(df_transpose.columns.tolist())\n",
    "\n",
    "# Flatten the list of columns from all files (if needed)\n",
    "all_columns = [col for sublist in all_columns for col in sublist]\n",
    "\n",
    "# Print the columns after transposing and adjusting column names\n",
    "print(all_columns)\n",
    "df_transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af53b3eb-439b-44ee-89ff-9a3dcba70458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
